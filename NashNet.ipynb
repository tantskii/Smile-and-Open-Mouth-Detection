{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.transform import resize\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/danil/Data/Datasets/MTFL'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>gender</th>\n",
       "      <th>smile</th>\n",
       "      <th>wearing glasses</th>\n",
       "      <th>head pose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lfw_5590\\Aaron_Eckhart_0001.jpg</td>\n",
       "      <td>107.25</td>\n",
       "      <td>147.75</td>\n",
       "      <td>126.25</td>\n",
       "      <td>106.25</td>\n",
       "      <td>140.75</td>\n",
       "      <td>108.75</td>\n",
       "      <td>113.25</td>\n",
       "      <td>143.75</td>\n",
       "      <td>158.75</td>\n",
       "      <td>162.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lfw_5590\\Aaron_Guiel_0001.jpg</td>\n",
       "      <td>101.25</td>\n",
       "      <td>146.75</td>\n",
       "      <td>125.25</td>\n",
       "      <td>93.75</td>\n",
       "      <td>139.75</td>\n",
       "      <td>112.25</td>\n",
       "      <td>117.75</td>\n",
       "      <td>137.75</td>\n",
       "      <td>160.75</td>\n",
       "      <td>164.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lfw_5590\\Aaron_Peirsol_0001.jpg</td>\n",
       "      <td>107.75</td>\n",
       "      <td>147.75</td>\n",
       "      <td>130.25</td>\n",
       "      <td>109.25</td>\n",
       "      <td>147.75</td>\n",
       "      <td>114.25</td>\n",
       "      <td>114.25</td>\n",
       "      <td>140.75</td>\n",
       "      <td>154.25</td>\n",
       "      <td>153.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lfw_5590\\Aaron_Pena_0001.jpg</td>\n",
       "      <td>102.75</td>\n",
       "      <td>146.25</td>\n",
       "      <td>126.25</td>\n",
       "      <td>120.75</td>\n",
       "      <td>147.25</td>\n",
       "      <td>117.75</td>\n",
       "      <td>104.75</td>\n",
       "      <td>137.75</td>\n",
       "      <td>164.75</td>\n",
       "      <td>156.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lfw_5590\\Aaron_Sorkin_0001.jpg</td>\n",
       "      <td>102.25</td>\n",
       "      <td>144.75</td>\n",
       "      <td>130.75</td>\n",
       "      <td>100.25</td>\n",
       "      <td>143.25</td>\n",
       "      <td>113.25</td>\n",
       "      <td>112.75</td>\n",
       "      <td>138.75</td>\n",
       "      <td>156.25</td>\n",
       "      <td>155.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path      x1      x2      x3      x4      x5  \\\n",
       "0  lfw_5590\\Aaron_Eckhart_0001.jpg  107.25  147.75  126.25  106.25  140.75   \n",
       "1    lfw_5590\\Aaron_Guiel_0001.jpg  101.25  146.75  125.25   93.75  139.75   \n",
       "2  lfw_5590\\Aaron_Peirsol_0001.jpg  107.75  147.75  130.25  109.25  147.75   \n",
       "3     lfw_5590\\Aaron_Pena_0001.jpg  102.75  146.25  126.25  120.75  147.25   \n",
       "4   lfw_5590\\Aaron_Sorkin_0001.jpg  102.25  144.75  130.75  100.25  143.25   \n",
       "\n",
       "       y1      y2      y3      y4      y5  gender  smile  wearing glasses  \\\n",
       "0  108.75  113.25  143.75  158.75  162.75     1.0    2.0              2.0   \n",
       "1  112.25  117.75  137.75  160.75  164.75     1.0    1.0              2.0   \n",
       "2  114.25  114.25  140.75  154.25  153.75     1.0    1.0              2.0   \n",
       "3  117.75  104.75  137.75  164.75  156.75     1.0    2.0              2.0   \n",
       "4  113.25  112.75  138.75  156.25  155.75     1.0    1.0              2.0   \n",
       "\n",
       "   head pose  \n",
       "0        3.0  \n",
       "1        3.0  \n",
       "2        3.0  \n",
       "3        3.0  \n",
       "4        3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv(os.path.join(path,'training.txt'), delimiter=\" \", header=None)\n",
    "training.drop(columns=[0], inplace=True)\n",
    "training.columns = ['path', 'x1', 'x2', 'x3', 'x4', 'x5', 'y1', 'y2', 'y3', 'y4', 'y5', 'gender', 'smile', 'wearing glasses', 'head pose']\n",
    "training.smile.fillna(2, inplace=True)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.smile = training.smile.map({2:0, 1:1})\n",
    "training['path'] = training['path'].apply(lambda x: str(x).replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "X_train_cv = skf.split(training.values, training['smile'].values)\n",
    "\n",
    "index_train_dict = {}\n",
    "index_test_dict = {}\n",
    "for i in range(5):\n",
    "    ind = next(X_train_cv)\n",
    "    index_train_dict['split_{}'.format(i)] = ind[0]\n",
    "    index_test_dict['split_{}'.format(i)] = ind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(train_id, training, batch_size = BATCH_SIZE):\n",
    "    training = training[training.index.isin(index_train_dict['split_0'])]\n",
    "    training = shuffle(training)\n",
    "    out_rgb = []\n",
    "    out_label = []\n",
    "    while True:\n",
    "        for path_img, smile in (training[['path', 'smile']].values):\n",
    "            out_rgb += [resize(imread(os.path.join(path, path_img)), (224,224,3))]\n",
    "            out_label += [smile]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0), np.stack(out_label, 0)\n",
    "                out_rgb, out_label=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_generator(index_train_dict['split_0'], training)\n",
    "val_gen = train_generator(index_test_dict['split_0'], training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import NASNetMobile\n",
    "model = NASNetMobile(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n",
    "\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(2048, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "\n",
    "from keras.models import Model\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "  \n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr=0.0001, decay=0.0001), metrics=['accuracy',auc,f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "weight_path='NashNet.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_auc', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only=False)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='f1', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    k = 0.1\n",
    "    lrate = initial_lrate * np.exp(-k*epoch)\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "\n",
    "callbacks_list = [checkpoint, lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 187s 747ms/step - loss: 1.2832 - acc: 0.6429 - auc: 0.6307 - f1: 0.6687 - val_loss: 0.9531 - val_acc: 0.8065 - val_auc: 0.7168 - val_f1: 0.8285\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.71682, saving model to NashNet.h5\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 141s 566ms/step - loss: 0.7890 - acc: 0.8830 - auc: 0.8003 - f1: 0.8928 - val_loss: 0.7472 - val_acc: 0.8958 - val_auc: 0.8584 - val_f1: 0.9072\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.71682 to 0.85839, saving model to NashNet.h5\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 142s 567ms/step - loss: 0.6292 - acc: 0.9471 - auc: 0.8926 - f1: 0.9516 - val_loss: 0.7023 - val_acc: 0.9137 - val_auc: 0.9166 - val_f1: 0.9215\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.85839 to 0.91659, saving model to NashNet.h5\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 145s 580ms/step - loss: 0.5495 - acc: 0.9735 - auc: 0.9324 - f1: 0.9754 - val_loss: 0.5652 - val_acc: 0.9653 - val_auc: 0.9458 - val_f1: 0.9688\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.91659 to 0.94582, saving model to NashNet.h5\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ea9aa5a0a5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                              callbacks = callbacks_list)]\n\u001b[0m",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "loss_history = [model_final.fit_generator(train_gen, \n",
    "                             steps_per_epoch = 8000/BATCH_SIZE, \n",
    "                             epochs = 10,\n",
    "                             validation_data = val_gen,\n",
    "                             validation_steps = 2000/BATCH_SIZE,\n",
    "                             callbacks = callbacks_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '/media/danil/Data/Datasets/example_data'\n",
    "test_images = os.listdir(os.path.join(path_test,'images'))\n",
    "test_images = [i for i in test_images if 'jpg' in i]\n",
    "\n",
    "test_smile = os.listdir(os.path.join(path_test,'smile'))\n",
    "test_smile = [i for i in test_smile if 'jpg' in i]\n",
    "\n",
    "test_open_mouth = os.listdir(os.path.join(path_test,'open_mouth'))\n",
    "test_open_mouth = [i for i in test_open_mouth if 'jpg' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mouth = []\n",
    "for i in test_images:\n",
    "    if i in test_open_mouth:\n",
    "        test_mouth += [1]\n",
    "    else:\n",
    "        test_mouth += [0]\n",
    "sum(test_mouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_smiles = []\n",
    "for i in test_images:\n",
    "    if i in test_smile:\n",
    "        test_smiles += [1]\n",
    "    else:\n",
    "        test_smiles += [0]\n",
    "sum(test_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['image'] = test_images\n",
    "test_df['smile'] = test_smiles\n",
    "test_df['mouth'] = test_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "test_images = [resize(imread(os.path.join(path_test,'images', i)), (224,224,3)) for i in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "predict = model_final.predict(np.stack(test_images, 0), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_smile = roc_auc_score(test_df.smile.values, predict)\n",
    "f1_score_smile = f1_score(test_df.smile.values, np.round(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1564625850340136\n"
     ]
    }
   ],
   "source": [
    "print(f1_score_smile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
