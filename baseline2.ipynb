{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyvips\n",
    "import warnings\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.utils import class_weight\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras.applications import DenseNet201\n",
    "from keras.layers import Dense, BatchNormalization, GlobalMaxPool2D\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import he_normal\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_REAL_FOLDER = 'D:/Datasets/IDRND Data/train/real'\n",
    "TRAIN_SPOOF_FOLDER = 'D:/Datasets/IDRND Data/train/spoof'\n",
    "VALIDATION_REAL_FOLDER = 'D:/Datasets/IDRND Data/validation/real'\n",
    "VALIDATION_SPOOF_FOLDER = 'D:/Datasets/IDRND Data/validation/spoof'\n",
    "TEST_FOLDER = 'D:/Datasets/IDRND Data/test'\n",
    "\n",
    "FOLDS = 5\n",
    "RANDOM_STATE = 17\n",
    "IMAGE_HEIGHT = 400\n",
    "IMAGE_WIDTH = 400\n",
    "BATCH_SIZE = 4\n",
    "REGULARIZER = 0.0001\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pyvips_image(path):\n",
    "    image = pyvips.Image.new_from_file(path, access='sequential')\n",
    "    memory_image = image.write_to_memory()\n",
    "    numpy_image = np.ndarray(buffer=memory_image,\n",
    "                             dtype=np.uint8,\n",
    "                             shape=[image.height, image.width, image.bands])\n",
    "    \n",
    "    return numpy_image\n",
    "\n",
    "def dataframe_to_fold_dict(dataframe, folds_indexes, fold_number, for_train=True):\n",
    "    if for_train:\n",
    "        fold = dataframe.iloc[folds_indexes[fold_number][0], :]\n",
    "    else:\n",
    "        fold = dataframe.iloc[folds_indexes[fold_number][1], :]\n",
    "    return dict(zip(fold['ImagePathway'], fold['Label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATION CREATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_names(folder, extension='*.png'):\n",
    "    image_names = fnmatch.filter(os.listdir(folder), extension)\n",
    "    return list(map(lambda image_name: os.path.join(folder, image_name), image_names))\n",
    "\n",
    "def get_merged_image_pathways(real_folder, spoof_folder):\n",
    "    return get_image_names(real_folder) + get_image_names(spoof_folder)\n",
    "\n",
    "real = pd.DataFrame({'ImagePathway': get_merged_image_pathways(TRAIN_REAL_FOLDER, VALIDATION_REAL_FOLDER),\n",
    "                     'Label': 0})\n",
    "spoof = pd.DataFrame({'ImagePathway': get_merged_image_pathways(TRAIN_SPOOF_FOLDER, VALIDATION_SPOOF_FOLDER),\n",
    "                      'Label': 1})\n",
    "\n",
    "train = pd.concat([real, spoof])\n",
    "train = train.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "folds_indexes = list(skf.split(train['ImagePathway'], train['Label']))\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train['Label']), train['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations_pipline = iaa.Sequential([\n",
    "    iaa.Sometimes(0.8, iaa.OneOf([\n",
    "        iaa.Multiply((0.3, 2.5), per_channel=0.5),\n",
    "        iaa.ContrastNormalization((0.5, 1.5), per_channel=0.8),\n",
    "        iaa.Grayscale(alpha=(0.5, 1.0)),\n",
    "    ])),\n",
    "    \n",
    "    iaa.OneOf([\n",
    "        iaa.Affine(scale=(1, 1.8), rotate=(0, 360), shear=(0, 20), backend='cv2'),\n",
    "        iaa.PerspectiveTransform(scale=(0.01, 0.10)),\n",
    "        iaa.PiecewiseAffine(scale=(0.01, 0.05)),\n",
    "        iaa.Sequential([\n",
    "            iaa.Fliplr(0.6),\n",
    "            iaa.Flipud(0.3),\n",
    "        ])\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, pathways_with_labels, augmentations_pipline=None, target_size=(400, 400, 3), batch_size=32, shuffle=True):\n",
    "        self.pathways_with_labels = pathways_with_labels\n",
    "        self.pathways = list(pathways_with_labels.keys())\n",
    "        self.augmentations_pipline = augmentations_pipline\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.pathways) / float(self.batch_size)))\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        batch_pathways = self.pathways[index*self.batch_size : (index + 1)*self.batch_size]\n",
    "        batch_size = np.minimum(self.batch_size, len(batch_pathways))\n",
    "        batch_x = np.empty((batch_size, *self.target_size), dtype=np.uint8)\n",
    "        batch_y = np.empty(batch_size, dtype=np.int)\n",
    "\n",
    "        for i, pathway in enumerate(batch_pathways):\n",
    "            image = read_pyvips_image(pathway)\n",
    "            image = imresize(image, (self.target_size[0], self.target_size[1]))\n",
    "            batch_x[i, ...] = image\n",
    "            batch_y[i] = self.pathways_with_labels[pathway]\n",
    "            \n",
    "        if self.augmentations_pipline:\n",
    "            batch_x = self.augmentations_pipline.augment_images(batch_x)\n",
    "            \n",
    "        batch_x = (batch_x / 256.) - 0.5\n",
    "        return batch_x, batch_y\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.pathways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = DenseNet201(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "gmp = GlobalMaxPool2D() (model_base.output)\n",
    "fc1 = Dense(1028,\n",
    "            activation='elu',\n",
    "            kernel_regularizer=l2(REGULARIZER),\n",
    "            kernel_initializer=he_normal(RANDOM_STATE),\n",
    "            use_bias=True,\n",
    "            bias_regularizer=l2(REGULARIZER),\n",
    "            bias_initializer=he_normal(RANDOM_STATE)) (gmp)\n",
    "bn1  = BatchNormalization() (fc1)\n",
    "fc2  = Dense(512,\n",
    "             activation='elu',\n",
    "             kernel_regularizer=l2(REGULARIZER),\n",
    "             kernel_initializer=he_normal(RANDOM_STATE),\n",
    "             use_bias=True,\n",
    "             bias_regularizer=l2(REGULARIZER),\n",
    "             bias_initializer=he_normal(RANDOM_STATE)) (bn1)\n",
    "bn2  = BatchNormalization() (fc2)\n",
    "output = Dense(1, activation='sigmoid') (bn2)\n",
    "\n",
    "model = Model(input=model_base.input, output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in model_base.layers:\n",
    "    if layer.name == 'global_max_pooling2d_1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING FREEZE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(y_true, y_pred):\n",
    "    roc_auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return roc_auc\n",
    "\n",
    "def roc_auc_loss(y_true, y_pred):\n",
    "    with tf.name_scope('RocAucScore'):\n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "        # original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.2\n",
    "        p     = 3\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "        return tf.reduce_sum(tf.pow(-masked, p))\n",
    "\n",
    "model.compile(loss=roc_auc_loss,\n",
    "              optimizer=SGD(0.001, momentum=0.9),\n",
    "              metrics=[roc_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    k = 0.1\n",
    "    learning_rate = initial_learning_rate * np.exp(-k*epoch)\n",
    "    return learning_rate\n",
    "\n",
    "learning_rate = LearningRateScheduler(exp_decay,\n",
    "                                      verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('DenseNet201_Freeze_Model1.h5',\n",
    "                                   monitor='val_roc_auc',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='max',\n",
    "                                   period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_roc_auc',\n",
    "                               min_delta=0,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               mode='max')\n",
    "callbacks = [early_stopping, learning_rate, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "1861/1861 [==============================] - 363s 195ms/step - loss: 0.4715 - roc_auc: 0.7377 - val_loss: 0.5421 - val_roc_auc: 0.7551\n",
      "\n",
      "Epoch 00001: val_roc_auc improved from -inf to 0.75514, saving model to DenseNet201_Freeze_Model1.h5\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "1861/1861 [==============================] - 319s 171ms/step - loss: 0.4231 - roc_auc: 0.7593 - val_loss: 0.4456 - val_roc_auc: 0.7580\n",
      "\n",
      "Epoch 00002: val_roc_auc improved from 0.75514 to 0.75804, saving model to DenseNet201_Freeze_Model1.h5\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "1861/1861 [==============================] - 305s 164ms/step - loss: 0.3947 - roc_auc: 0.7572 - val_loss: 0.5652 - val_roc_auc: 0.7615\n",
      "\n",
      "Epoch 00003: val_roc_auc improved from 0.75804 to 0.76148, saving model to DenseNet201_Freeze_Model1.h5\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "1861/1861 [==============================] - 322s 173ms/step - loss: 0.3680 - roc_auc: 0.7654 - val_loss: 0.5380 - val_roc_auc: 0.7700\n",
      "\n",
      "Epoch 00004: val_roc_auc improved from 0.76148 to 0.76996, saving model to DenseNet201_Freeze_Model1.h5\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "1861/1861 [==============================] - 312s 168ms/step - loss: 0.3721 - roc_auc: 0.7722 - val_loss: 0.3852 - val_roc_auc: 0.7715\n",
      "\n",
      "Epoch 00005: val_roc_auc improved from 0.76996 to 0.77154, saving model to DenseNet201_Freeze_Model1.h5\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "1861/1861 [==============================] - 329s 177ms/step - loss: 0.3491 - roc_auc: 0.7726 - val_loss: 0.4721 - val_roc_auc: 0.7751\n",
      "\n",
      "Epoch 00006: val_roc_auc improved from 0.77154 to 0.77506, saving model to DenseNet201_Freeze_Model1.h5\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0005488116360940264.\n",
      "1861/1861 [==============================] - 327s 176ms/step - loss: 0.3402 - roc_auc: 0.7771 - val_loss: 0.4773 - val_roc_auc: 0.7783\n",
      "\n",
      "Epoch 00007: val_roc_auc improved from 0.77506 to 0.77834, saving model to DenseNet201_Freeze_Model1.h5\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0004965853037914095.\n",
      "1861/1861 [==============================] - 329s 177ms/step - loss: 0.3329 - roc_auc: 0.7772 - val_loss: 0.4112 - val_roc_auc: 0.7768\n",
      "\n",
      "Epoch 00008: val_roc_auc did not improve from 0.77834\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0004493289641172216.\n",
      "1861/1861 [==============================] - 344s 185ms/step - loss: 0.3261 - roc_auc: 0.7762 - val_loss: 0.4458 - val_roc_auc: 0.7755\n",
      "\n",
      "Epoch 00009: val_roc_auc did not improve from 0.77834\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.00040656965974059914.\n",
      "1861/1861 [==============================] - 343s 184ms/step - loss: 0.3234 - roc_auc: 0.7752 - val_loss: 0.4040 - val_roc_auc: 0.7750\n",
      "\n",
      "Epoch 00010: val_roc_auc did not improve from 0.77834\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "fold_train_pathways_with_labels = dataframe_to_fold_dict(train, \n",
    "                                                         folds_indexes=folds_indexes, \n",
    "                                                         fold_number=1, \n",
    "                                                         for_train=True)\n",
    "\n",
    "fold_valid_pathways_with_labels = dataframe_to_fold_dict(train, \n",
    "                                                         folds_indexes=folds_indexes, \n",
    "                                                         fold_number=1, \n",
    "                                                         for_train=False)\n",
    "\n",
    "train_generator = DataGenerator(fold_train_pathways_with_labels,\n",
    "                                augmentations_pipline=augmentations_pipline,\n",
    "                                target_size=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True)\n",
    "\n",
    "valid_generator = DataGenerator(fold_valid_pathways_with_labels,\n",
    "                                augmentations_pipline=None,\n",
    "                                target_size=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True)\n",
    "\n",
    "history = [model.fit_generator(train_generator,\n",
    "                               epochs=10,\n",
    "                               callbacks=callbacks,\n",
    "                               validation_data=valid_generator,\n",
    "                               verbose=1,\n",
    "                               class_weight=class_weights,\n",
    "                               workers=4,\n",
    "                               use_multiprocessing=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('DenseNet201_Freeze_Model1.h5', custom_objects={'roc_auc_loss': roc_auc_loss, 'roc_auc': roc_auc})\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_learning_rate = 0.0001\n",
    "    k = 0.1\n",
    "    learning_rate = initial_learning_rate * np.exp(-k*epoch)\n",
    "    \n",
    "    return learning_rate\n",
    "\n",
    "learning_rate = LearningRateScheduler(exp_decay, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('DenseNet201_Model1.h5',\n",
    "                                   monitor='val_roc_auc',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='max',\n",
    "                                   period=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_roc_auc',\n",
    "                               min_delta=0,\n",
    "                               patience=10,\n",
    "                               verbose=1,\n",
    "                               mode='max')\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint, learning_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1861/1861 [==============================] - 835s 449ms/step - loss: 0.8907 - acc: 0.6355 - roc_auc: 0.7587 - val_loss: 0.5452 - val_acc: 0.8802 - val_roc_auc: 0.7788\n",
      "\n",
      "Epoch 00001: val_roc_auc improved from -inf to 0.77884, saving model to DenseNet201_Model1.h5\n",
      "Epoch 2/70\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 9.048374180359596e-05.\n",
      "1861/1861 [==============================] - 723s 388ms/step - loss: 0.4695 - acc: 0.8748 - roc_auc: 0.7990 - val_loss: 0.3223 - val_acc: 0.9420 - val_roc_auc: 0.8181\n",
      "\n",
      "Epoch 00002: val_roc_auc improved from 0.77884 to 0.81805, saving model to DenseNet201_Model1.h5\n",
      "Epoch 3/70\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 8.187307530779819e-05.\n",
      "1861/1861 [==============================] - 712s 383ms/step - loss: 0.4135 - acc: 0.9005 - roc_auc: 0.8350 - val_loss: 0.2558 - val_acc: 0.9721 - val_roc_auc: 0.8522\n",
      "\n",
      "Epoch 00003: val_roc_auc improved from 0.81805 to 0.85216, saving model to DenseNet201_Model1.h5\n",
      "Epoch 4/70\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 7.408182206817179e-05.\n",
      "1861/1861 [==============================] - 734s 395ms/step - loss: 0.3745 - acc: 0.9161 - roc_auc: 0.8664 - val_loss: 0.2252 - val_acc: 0.9710 - val_roc_auc: 0.8776\n",
      "\n",
      "Epoch 00004: val_roc_auc improved from 0.85216 to 0.87761, saving model to DenseNet201_Model1.h5\n",
      "Epoch 5/70\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 6.703200460356394e-05.\n",
      "1861/1861 [==============================] - 729s 392ms/step - loss: 0.3343 - acc: 0.9285 - roc_auc: 0.8886 - val_loss: 0.2491 - val_acc: 0.9688 - val_roc_auc: 0.8972\n",
      "\n",
      "Epoch 00005: val_roc_auc improved from 0.87761 to 0.89725, saving model to DenseNet201_Model1.h5\n",
      "Epoch 6/70\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 6.065306597126335e-05.\n",
      "1861/1861 [==============================] - 721s 387ms/step - loss: 0.3030 - acc: 0.9425 - roc_auc: 0.9050 - val_loss: 0.1798 - val_acc: 0.9871 - val_roc_auc: 0.9126\n",
      "\n",
      "Epoch 00006: val_roc_auc improved from 0.89725 to 0.91256, saving model to DenseNet201_Model1.h5\n",
      "Epoch 7/70\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 5.488116360940264e-05.\n",
      "1861/1861 [==============================] - 720s 387ms/step - loss: 0.2730 - acc: 0.9512 - roc_auc: 0.9196 - val_loss: 0.1985 - val_acc: 0.9893 - val_roc_auc: 0.9252\n",
      "\n",
      "Epoch 00007: val_roc_auc improved from 0.91256 to 0.92521, saving model to DenseNet201_Model1.h5\n",
      "Epoch 8/70\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 4.965853037914095e-05.\n",
      "1861/1861 [==============================] - 717s 385ms/step - loss: 0.2477 - acc: 0.9592 - roc_auc: 0.9308 - val_loss: 0.1839 - val_acc: 0.9903 - val_roc_auc: 0.9355\n",
      "\n",
      "Epoch 00008: val_roc_auc improved from 0.92521 to 0.93552, saving model to DenseNet201_Model1.h5\n",
      "Epoch 9/70\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 4.493289641172216e-05.\n",
      "1861/1861 [==============================] - 710s 382ms/step - loss: 0.2521 - acc: 0.9592 - roc_auc: 0.9393 - val_loss: 0.1962 - val_acc: 0.9780 - val_roc_auc: 0.9426\n",
      "\n",
      "Epoch 00009: val_roc_auc improved from 0.93552 to 0.94263, saving model to DenseNet201_Model1.h5\n",
      "Epoch 10/70\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 4.0656965974059915e-05.\n",
      "1861/1861 [==============================] - 747s 401ms/step - loss: 0.2241 - acc: 0.9692 - roc_auc: 0.9458 - val_loss: 0.1571 - val_acc: 0.9919 - val_roc_auc: 0.9490\n",
      "\n",
      "Epoch 00010: val_roc_auc improved from 0.94263 to 0.94904, saving model to DenseNet201_Model1.h5\n",
      "Epoch 11/70\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 3.678794411714424e-05.\n",
      "1861/1861 [==============================] - 726s 390ms/step - loss: 0.2223 - acc: 0.9707 - roc_auc: 0.9517 - val_loss: 0.1661 - val_acc: 0.9952 - val_roc_auc: 0.9541\n",
      "\n",
      "Epoch 00011: val_roc_auc improved from 0.94904 to 0.95408, saving model to DenseNet201_Model1.h5\n",
      "Epoch 12/70\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 3.3287108369807955e-05.\n",
      "1861/1861 [==============================] - 714s 383ms/step - loss: 0.2040 - acc: 0.9739 - roc_auc: 0.9565 - val_loss: 0.1611 - val_acc: 0.9941 - val_roc_auc: 0.9587\n",
      "\n",
      "Epoch 00012: val_roc_auc improved from 0.95408 to 0.95873, saving model to DenseNet201_Model1.h5\n",
      "Epoch 13/70\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 3.0119421191220204e-05.\n",
      "1861/1861 [==============================] - 758s 407ms/step - loss: 0.1954 - acc: 0.9770 - roc_auc: 0.9607 - val_loss: 0.1482 - val_acc: 0.9941 - val_roc_auc: 0.9626\n",
      "\n",
      "Epoch 00013: val_roc_auc improved from 0.95873 to 0.96260, saving model to DenseNet201_Model1.h5\n",
      "Epoch 14/70\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 2.725317930340126e-05.\n",
      "1861/1861 [==============================] - 756s 406ms/step - loss: 0.1955 - acc: 0.9791 - roc_auc: 0.9642 - val_loss: 0.1422 - val_acc: 0.9962 - val_roc_auc: 0.9658\n",
      "\n",
      "Epoch 00014: val_roc_auc improved from 0.96260 to 0.96585, saving model to DenseNet201_Model1.h5\n",
      "Epoch 15/70\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 2.4659696394160646e-05.\n",
      "1861/1861 [==============================] - 739s 397ms/step - loss: 0.1785 - acc: 0.9831 - roc_auc: 0.9674 - val_loss: 0.1411 - val_acc: 0.9962 - val_roc_auc: 0.9689\n",
      "\n",
      "Epoch 00015: val_roc_auc improved from 0.96585 to 0.96894, saving model to DenseNet201_Model1.h5\n",
      "Epoch 16/70\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 2.2313016014842984e-05.\n",
      "1861/1861 [==============================] - 751s 404ms/step - loss: 0.1945 - acc: 0.9780 - roc_auc: 0.9700 - val_loss: 0.1466 - val_acc: 0.9952 - val_roc_auc: 0.9711\n",
      "\n",
      "Epoch 00016: val_roc_auc improved from 0.96894 to 0.97107, saving model to DenseNet201_Model1.h5\n",
      "Epoch 17/70\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 2.018965179946554e-05.\n",
      "1861/1861 [==============================] - 751s 404ms/step - loss: 0.1793 - acc: 0.9816 - roc_auc: 0.9722 - val_loss: 0.1405 - val_acc: 0.9973 - val_roc_auc: 0.9733\n",
      "\n",
      "Epoch 00017: val_roc_auc improved from 0.97107 to 0.97327, saving model to DenseNet201_Model1.h5\n",
      "Epoch 18/70\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 1.8268352405273462e-05.\n",
      "1861/1861 [==============================] - 763s 410ms/step - loss: 0.1746 - acc: 0.9850 - roc_auc: 0.9742 - val_loss: 0.1388 - val_acc: 0.9973 - val_roc_auc: 0.9752\n",
      "\n",
      "Epoch 00018: val_roc_auc improved from 0.97327 to 0.97515, saving model to DenseNet201_Model1.h5\n",
      "Epoch 19/70\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 1.6529888822158655e-05.\n",
      "1861/1861 [==============================] - 740s 398ms/step - loss: 0.1751 - acc: 0.9855 - roc_auc: 0.9760 - val_loss: 0.1406 - val_acc: 0.9957 - val_roc_auc: 0.9768\n",
      "\n",
      "Epoch 00019: val_roc_auc improved from 0.97515 to 0.97680, saving model to DenseNet201_Model1.h5\n",
      "Epoch 20/70\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 1.4956861922263504e-05.\n",
      "1861/1861 [==============================] - 743s 399ms/step - loss: 0.1807 - acc: 0.9823 - roc_auc: 0.9774 - val_loss: 0.1384 - val_acc: 0.9962 - val_roc_auc: 0.9780\n",
      "\n",
      "Epoch 00020: val_roc_auc improved from 0.97680 to 0.97797, saving model to DenseNet201_Model1.h5\n",
      "Epoch 21/70\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 1.353352832366127e-05.\n",
      "1861/1861 [==============================] - 746s 401ms/step - loss: 0.1737 - acc: 0.9846 - roc_auc: 0.9786 - val_loss: 0.1372 - val_acc: 0.9973 - val_roc_auc: 0.9792\n",
      "\n",
      "Epoch 00021: val_roc_auc improved from 0.97797 to 0.97924, saving model to DenseNet201_Model1.h5\n",
      "Epoch 22/70\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 1.2245642825298192e-05.\n",
      "1861/1861 [==============================] - 744s 400ms/step - loss: 0.1704 - acc: 0.9864 - roc_auc: 0.9798 - val_loss: 0.1345 - val_acc: 0.9968 - val_roc_auc: 0.9804\n",
      "\n",
      "Epoch 00022: val_roc_auc improved from 0.97924 to 0.98037, saving model to DenseNet201_Model1.h5\n",
      "Epoch 23/70\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 1.1080315836233388e-05.\n",
      "1861/1861 [==============================] - 747s 401ms/step - loss: 0.1723 - acc: 0.9850 - roc_auc: 0.9809 - val_loss: 0.1338 - val_acc: 0.9973 - val_roc_auc: 0.9814\n",
      "\n",
      "Epoch 00023: val_roc_auc improved from 0.98037 to 0.98136, saving model to DenseNet201_Model1.h5\n",
      "Epoch 24/70\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 1.0025884372280372e-05.\n",
      "1861/1861 [==============================] - 748s 402ms/step - loss: 0.1778 - acc: 0.9847 - roc_auc: 0.9817 - val_loss: 0.1388 - val_acc: 0.9952 - val_roc_auc: 0.9821\n",
      "\n",
      "Epoch 00024: val_roc_auc improved from 0.98136 to 0.98211, saving model to DenseNet201_Model1.h5\n",
      "Epoch 25/70\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 9.071795328941247e-06.\n",
      "1861/1861 [==============================] - 749s 403ms/step - loss: 0.1624 - acc: 0.9885 - roc_auc: 0.9826 - val_loss: 0.1357 - val_acc: 0.9968 - val_roc_auc: 0.9830\n",
      "\n",
      "Epoch 00025: val_roc_auc improved from 0.98211 to 0.98299, saving model to DenseNet201_Model1.h5\n",
      "Epoch 26/70\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 8.20849986238988e-06.\n",
      "1861/1861 [==============================] - 752s 404ms/step - loss: 0.1727 - acc: 0.9860 - roc_auc: 0.9834 - val_loss: 0.1361 - val_acc: 0.9979 - val_roc_auc: 0.9836\n",
      "\n",
      "Epoch 00026: val_roc_auc improved from 0.98299 to 0.98364, saving model to DenseNet201_Model1.h5\n",
      "Epoch 27/70\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 7.427357821433388e-06.\n",
      "1861/1861 [==============================] - 748s 402ms/step - loss: 0.1711 - acc: 0.9864 - roc_auc: 0.9839 - val_loss: 0.1352 - val_acc: 0.9968 - val_roc_auc: 0.9842\n",
      "\n",
      "Epoch 00027: val_roc_auc improved from 0.98364 to 0.98423, saving model to DenseNet201_Model1.h5\n",
      "Epoch 28/70\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 6.720551273974976e-06.\n",
      "1861/1861 [==============================] - 746s 401ms/step - loss: 0.1619 - acc: 0.9871 - roc_auc: 0.9846 - val_loss: 0.1351 - val_acc: 0.9968 - val_roc_auc: 0.9849\n",
      "\n",
      "Epoch 00028: val_roc_auc improved from 0.98423 to 0.98491, saving model to DenseNet201_Model1.h5\n",
      "Epoch 29/70\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 6.081006262521795e-06.\n",
      "1861/1861 [==============================] - 747s 401ms/step - loss: 0.1644 - acc: 0.9884 - roc_auc: 0.9852 - val_loss: 0.1337 - val_acc: 0.9979 - val_roc_auc: 0.9855\n",
      "\n",
      "Epoch 00029: val_roc_auc improved from 0.98491 to 0.98549, saving model to DenseNet201_Model1.h5\n",
      "Epoch 30/70\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 5.502322005640721e-06.\n",
      "1861/1861 [==============================] - 750s 403ms/step - loss: 0.1603 - acc: 0.9878 - roc_auc: 0.9858 - val_loss: 0.1325 - val_acc: 0.9979 - val_roc_auc: 0.9861\n",
      "\n",
      "Epoch 00030: val_roc_auc improved from 0.98549 to 0.98605, saving model to DenseNet201_Model1.h5\n",
      "Epoch 31/70\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 4.978706836786395e-06.\n",
      "1861/1861 [==============================] - 750s 403ms/step - loss: 0.1677 - acc: 0.9876 - roc_auc: 0.9863 - val_loss: 0.1342 - val_acc: 0.9968 - val_roc_auc: 0.9865\n",
      "\n",
      "Epoch 00031: val_roc_auc improved from 0.98605 to 0.98646, saving model to DenseNet201_Model1.h5\n",
      "Epoch 32/70\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 4.50492023935578e-06.\n",
      "1861/1861 [==============================] - 750s 403ms/step - loss: 0.1697 - acc: 0.9866 - roc_auc: 0.9867 - val_loss: 0.1322 - val_acc: 0.9979 - val_roc_auc: 0.9868\n",
      "\n",
      "Epoch 00032: val_roc_auc improved from 0.98646 to 0.98683, saving model to DenseNet201_Model1.h5\n",
      "Epoch 33/70\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 4.0762203978366214e-06.\n",
      "1861/1861 [==============================] - 747s 401ms/step - loss: 0.1556 - acc: 0.9909 - roc_auc: 0.9871 - val_loss: 0.1322 - val_acc: 0.9984 - val_roc_auc: 0.9873\n",
      "\n",
      "Epoch 00033: val_roc_auc improved from 0.98683 to 0.98731, saving model to DenseNet201_Model1.h5\n",
      "Epoch 34/70\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 3.6883167401239998e-06.\n",
      "1861/1861 [==============================] - 744s 400ms/step - loss: 0.1604 - acc: 0.9886 - roc_auc: 0.9875 - val_loss: 0.1325 - val_acc: 0.9973 - val_roc_auc: 0.9877\n",
      "\n",
      "Epoch 00034: val_roc_auc improved from 0.98731 to 0.98774, saving model to DenseNet201_Model1.h5\n",
      "Epoch 35/70\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 3.337326996032607e-06.\n",
      "1861/1861 [==============================] - 743s 399ms/step - loss: 0.1593 - acc: 0.9883 - roc_auc: 0.9880 - val_loss: 0.1324 - val_acc: 0.9979 - val_roc_auc: 0.9882\n",
      "\n",
      "Epoch 00035: val_roc_auc improved from 0.98774 to 0.98815, saving model to DenseNet201_Model1.h5\n",
      "Epoch 36/70\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 3.0197383422318503e-06.\n",
      "1861/1861 [==============================] - 739s 397ms/step - loss: 0.1589 - acc: 0.9880 - roc_auc: 0.9883 - val_loss: 0.1325 - val_acc: 0.9979 - val_roc_auc: 0.9885\n",
      "\n",
      "Epoch 00036: val_roc_auc improved from 0.98815 to 0.98852, saving model to DenseNet201_Model1.h5\n",
      "Epoch 37/70\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 2.732372244729256e-06.\n",
      "1861/1861 [==============================] - 739s 397ms/step - loss: 0.1617 - acc: 0.9889 - roc_auc: 0.9887 - val_loss: 0.1326 - val_acc: 0.9979 - val_roc_auc: 0.9888\n",
      "\n",
      "Epoch 00037: val_roc_auc improved from 0.98852 to 0.98883, saving model to DenseNet201_Model1.h5\n",
      "Epoch 38/70\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 2.472352647033939e-06.\n",
      "1861/1861 [==============================] - 739s 397ms/step - loss: 0.1616 - acc: 0.9863 - roc_auc: 0.9890 - val_loss: 0.1333 - val_acc: 0.9968 - val_roc_auc: 0.9892\n",
      "\n",
      "Epoch 00038: val_roc_auc improved from 0.98883 to 0.98916, saving model to DenseNet201_Model1.h5\n",
      "Epoch 39/70\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 2.2370771856165594e-06.\n",
      "1861/1861 [==============================] - 739s 397ms/step - loss: 0.1623 - acc: 0.9870 - roc_auc: 0.9893 - val_loss: 0.1317 - val_acc: 0.9979 - val_roc_auc: 0.9894\n",
      "\n",
      "Epoch 00039: val_roc_auc improved from 0.98916 to 0.98942, saving model to DenseNet201_Model1.h5\n",
      "Epoch 40/70\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 2.0241911445804383e-06.\n",
      "1861/1861 [==============================] - 740s 398ms/step - loss: 0.1657 - acc: 0.9868 - roc_auc: 0.9896 - val_loss: 0.1324 - val_acc: 0.9979 - val_roc_auc: 0.9897\n",
      "\n",
      "Epoch 00040: val_roc_auc improved from 0.98942 to 0.98967, saving model to DenseNet201_Model1.h5\n",
      "Epoch 41/70\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 1.8315638888734179e-06.\n",
      "1861/1861 [==============================] - 736s 396ms/step - loss: 0.1607 - acc: 0.9882 - roc_auc: 0.9898 - val_loss: 0.1320 - val_acc: 0.9973 - val_roc_auc: 0.9899\n",
      "\n",
      "Epoch 00041: val_roc_auc improved from 0.98967 to 0.98992, saving model to DenseNet201_Model1.h5\n",
      "Epoch 42/70\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 1.6572675401761238e-06.\n",
      "1861/1861 [==============================] - 735s 395ms/step - loss: 0.1642 - acc: 0.9874 - roc_auc: 0.9900 - val_loss: 0.1330 - val_acc: 0.9968 - val_roc_auc: 0.9901\n",
      "\n",
      "Epoch 00042: val_roc_auc improved from 0.98992 to 0.99013, saving model to DenseNet201_Model1.h5\n",
      "Epoch 43/70\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 1.4995576820477704e-06.\n",
      "1861/1861 [==============================] - 735s 395ms/step - loss: 0.1572 - acc: 0.9897 - roc_auc: 0.9903 - val_loss: 0.1324 - val_acc: 0.9973 - val_roc_auc: 0.9904\n",
      "\n",
      "Epoch 00043: val_roc_auc improved from 0.99013 to 0.99037, saving model to DenseNet201_Model1.h5\n",
      "Epoch 44/70\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 1.3568559012200934e-06.\n",
      "1861/1861 [==============================] - 735s 395ms/step - loss: 0.1609 - acc: 0.9878 - roc_auc: 0.9905 - val_loss: 0.1322 - val_acc: 0.9979 - val_roc_auc: 0.9906\n",
      "\n",
      "Epoch 00044: val_roc_auc improved from 0.99037 to 0.99060, saving model to DenseNet201_Model1.h5\n",
      "Epoch 45/70\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 1.2277339903068436e-06.\n",
      "1860/1861 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9862 - roc_auc: 0.9907"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=0.0001),\n",
    "              metrics=['accuracy', roc_auc])\n",
    "\n",
    "history = [model.fit_generator(train_generator,\n",
    "                               epochs=70,\n",
    "                               callbacks=callbacks,\n",
    "                               validation_data=valid_generator,\n",
    "                               verbose=1,\n",
    "                               class_weight=class_weights,\n",
    "                               workers=4,\n",
    "                               use_multiprocessing=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
